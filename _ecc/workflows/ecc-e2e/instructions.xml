<workflow name="ecc-e2e" version="1.0">

  <orchestrator-protocol>
    <critical>You are the ECC E2E Orchestrator. You run E2E testing as a standalone concern.</critical>
    <critical>Pre-flight is MANDATORY. No test code is written until all 4 pre-flight checks pass or get explicit user exception.</critical>
    <critical>All tests run ONLY against staging (localhost:5174 with staging backend).</critical>

    <available-agents>
      | Agent | subagent_type | Purpose |
      |-------|---------------|---------|
      | E2E Runner | everything-claude-code:e2e-runner | Write and run E2E tests |
      | Code Reviewer | everything-claude-code:code-reviewer | Post-test quality review |
    </available-agents>
  </orchestrator-protocol>

  <!-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê -->
  <!-- STEP 0: Load E2E Knowledge                                             -->
  <!-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê -->

  <step n="0" goal="Load and cache E2E knowledge for the session" tag="knowledge-init">
    <critical>Load ALL knowledge ONCE. These inform pre-flight checks and agent prompts.</critical>

    <action>Load and cache tests/e2e/E2E-TEST-CONVENTIONS.md ‚Üí {{e2e_conventions}}</action>
    <action>Load and cache .claude/rules/testing.md ‚Üí {{testing_rules}}</action>
    <action>Load and cache tests/e2e/helpers/staging-helpers.ts ‚Üí {{staging_helpers_api}}</action>
    <action>Load and cache tests/e2e/helpers/cooldown-reset.ts ‚Üí {{cooldown_helpers}} (if exists)</action>
    <action>Load and cache _bmad/tea/testarch/knowledge/playwright-cli.md ‚Üí {{playwright_cli_knowledge}}</action>
    <action>Load and cache _bmad/tea/testarch/knowledge/selector-resilience.md ‚Üí {{selector_patterns}}</action>

    <output>üìö **ECC E2E Orchestrator Initialized**

      Knowledge loaded:
      - E2E conventions: {{e2e_conventions_summary}}
      - Testing rules: pre-flight checklist loaded
      - Staging helpers: {{helper_count}} functions available
      - TEA knowledge: playwright-cli, selector-resilience
    </output>
  </step>

  <!-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê -->
  <!-- STEP 1: Analyze Story for E2E Need                                     -->
  <!-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê -->

  <step n="1" goal="Determine E2E action: SKIP, VERIFY, EXTEND, or CREATE" tag="analysis">

    <!-- Input collection -->
    <action>Detect story from branch name or user argument:
      - If user passed story key ‚Üí load story from sprint_artifacts
      - If user passed directory ‚Üí use as scope
      - Else ‚Üí extract story key from current branch name (feature/{{story_key}})
    </action>

    <action>Run `git diff develop...HEAD --name-only` ‚Üí {{changed_files}}</action>
    <action>If story file found, extract File Specification and ACs ‚Üí {{story_context}}</action>
    <action>Filter changed files to UI components (.tsx in components/views, not types/utils) ‚Üí {{changed_ui_files}}</action>

    <!-- Auto-classification -->
    <action>Classify E2E action:
      1. If no UI files in {{changed_ui_files}} and no user-flow ACs ‚Üí SKIP
      2. Search tests/e2e/staging/*.spec.ts for TestIds matching {{changed_ui_files}}
      3. If match found and all relevant ACs already covered ‚Üí VERIFY
      4. If match found but new ACs not covered ‚Üí EXTEND
      5. If no match ‚Üí CREATE
    </action>

    <action>Set {{e2e_action}} = SKIP | VERIFY | EXTEND | CREATE</action>
    <action>Set {{target_spec}} = matching spec file (for VERIFY/EXTEND) or new file path (for CREATE)</action>

    <!-- Present to user -->
    <ask>**E2E Analysis: {{e2e_action}}**

      Story: {{story_key}}
      Changed UI: {{changed_ui_files}}
      {{#if target_spec}}Existing spec: {{target_spec}}{{/if}}
      {{#if e2e_gap}}Gap: {{e2e_gap}}{{/if}}

      Proceed with {{e2e_action}}? [Y / N / Override]</ask>

    <check if="e2e_action == SKIP and user confirms">
      <output>‚è≠Ô∏è **E2E not needed** ‚Äî {{skip_reason}}</output>
      <action>Jump to Step 7 (update story with "E2E: SKIP" note)</action>
    </check>

    <check if="e2e_action == VERIFY">
      <action>Run existing spec: `npx playwright test {{target_spec}} --project=staging`</action>
      <check if="test passes">
        <output>‚úÖ **Existing E2E spec passes** ‚Äî no changes needed</output>
        <action>Jump to Step 7 (update story with "E2E: VERIFY ‚Äî existing spec passes")</action>
      </check>
      <check if="test fails">
        <output>‚ö†Ô∏è Existing spec FAILS ‚Äî switching to EXTEND mode to fix</output>
        <action>Set {{e2e_action}} = EXTEND</action>
      </check>
    </check>
  </step>

  <!-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê -->
  <!-- STEP 2: Pre-Flight Checklist (MANDATORY)                               -->
  <!-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê -->

  <step n="2" goal="Complete all 4 pre-flight checks before writing any test code" tag="pre-flight">
    <critical>üö® NO test code is written until all 4 checks pass or get explicit user exception.</critical>

    <!-- 2a: TestId Discovery -->
    <action>**2a: TestId Discovery (Playwright CLI auto-mode)**

      1. Check if dev:staging is running: `curl -s -o /dev/null -w "%{http_code}" http://localhost:5174`
      2. If running (200) ‚Üí use playwright-cli for TestId extraction:
         - Open target page(s) that {{changed_ui_files}} render
         - Run snapshot ‚Üí extract element refs (roles, labels, data-testid)
         - ~93% fewer tokens than reading full component source
      3. If NOT running ‚Üí fallback to source file reading:
         - Read each .tsx component, grep for data-testid attributes
         - Read src/utils/translations.ts for button/label text
         - Warn user: "Start dev:staging for better TestId discovery via Playwright CLI"
      4. If MCP Playwright tools available ‚Üí use for richer DOM introspection

      Output: {{testid_map}} ‚Äî all interactive elements on target views
    </action>

    <!-- 2b: Data Flow Analysis -->
    <action>**2b: Data Flow Analysis**

      For EVERY mutation the test will trigger:
      1. Read the service function (e.g., groupService.ts) ‚Äî understand the Firestore write
      2. Read the hook (e.g., useGroups.ts) ‚Äî find optimistic update patterns
      3. Search for: PENDING, temp-, loading, optimistic in hook code
      4. If optimistic updates exist ‚Üí plan polling/retry logic BEFORE writing test
      5. Document expected state transitions

      Output: {{data_flow_map}} ‚Äî mutations, optimistic patterns, expected transitions
    </action>

    <!-- 2c: Environment Readiness -->
    <action>**2c: Environment Readiness**

      1. Read firestore.rules for collections the feature accesses
      2. Verify rules allow the test's operations (cross-user reads, group access patterns)
      3. Check if Cloud Functions are required and deployed to staging
      4. Verify test users exist (alice, bob, charlie, diana)

      Output: {{env_readiness}} ‚Äî pass/fail with details
    </action>

    <!-- 2d: Cleanup Strategy -->
    <action>**2d: Cleanup Strategy**

      1. Determine data created during test (groups, invitations, preferences)
      2. Plan try/finally cleanup from the start
      3. Name test data: "E2E" prefix + Date.now() suffix for targeting
      4. For multi-user: plan bidirectional cleanup (member leaves ‚Üí owner deletes)
      5. Check if cooldown resets are needed (sharing toggle, etc.)

      Output: {{cleanup_plan}} ‚Äî cleanup sequence, cooldown resets, residual data handling
    </action>

    <!-- Exception handling -->
    <check if="any pre-flight check fails">
      <ask>‚ö†Ô∏è Pre-flight check failed: {{failed_check}}

        Issue: {{issue_description}}
        Recommendation: {{recommendation}}

        [F]ix (attempt to resolve) / [S]kip (proceed with known risk) / [A]bort</ask>

      <check if="user chooses S (Skip)">
        <output>‚ö†Ô∏è Proceeding with known risk: {{failed_check}} skipped by user</output>
      </check>
      <check if="user chooses A (Abort)">
        <output>üõë E2E workflow aborted. Fix {{failed_check}} and re-run /ecc-e2e</output>
        <action>Stop workflow</action>
      </check>
    </check>

    <output>‚úÖ **Pre-Flight Complete**

      - TestId Map: {{testid_count}} elements discovered
      - Data Flow: {{mutation_count}} mutations mapped
      - Environment: {{env_readiness}}
      - Cleanup: {{cleanup_summary}}
    </output>
  </step>

  <!-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê -->
  <!-- STEP 3: Multi-User Detection and Strategy                              -->
  <!-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê -->

  <step n="3" goal="Auto-detect multi-user need and recommend approach" tag="multi-user">

    <action>Detect multi-user indicators:
      - Story mentions: sharing, invitation, join, group membership, cross-user
      - Changed files include: invitationService, groupService with member operations
      - ACs mention multiple user perspectives ("owner sees...", "member sees...")
      - Existing related tests use multi-user pattern (browser contexts)
    </action>

    <check if="multi-user indicators found">
      <action>Determine pattern:
        - CONCURRENT: users must see each other's actions in same session
          ‚Üí Separate browser contexts (browser.newContext()), both open simultaneously
        - SEQUENTIAL: users act independently in sequence
          ‚Üí Single page, login/logout between users via TestUserMenu
      </action>

      <action>Determine cleanup order:
        - CONCURRENT: bidirectional (member leaves ‚Üí owner deletes ‚Üí close contexts)
        - SEQUENTIAL: single-direction (last user cleans up)
      </action>

      <action>Check cooldown resets:
        - If test involves sharing toggle ‚Üí import resetAllCooldowns from helpers/cooldown-reset.ts
        - Call in test setup BEFORE toggle operations
      </action>

      <ask>**Multi-User Analysis**

        Pattern: {{multi_user_pattern}} ({{pattern_reason}})
        Users: {{user_a}} ({{role_a}}), {{user_b}} ({{role_b}})

        Approach:
        {{multi_user_approach}}

        Cleanup:
        {{cleanup_order}}

        Cooldown resets: {{cooldown_needed}}

        Proceed? [Y / N / Adjust]</ask>
    </check>

    <check if="no multi-user indicators">
      <action>Set {{multi_user_strategy}} = "SINGLE-USER ‚Äî standard staging test pattern"</action>
    </check>
  </step>

  <!-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê -->
  <!-- STEP 4: Write/Extend E2E Test                                          -->
  <!-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê -->

  <step n="4" goal="Spawn e2e-runner agent to write or extend test" tag="write-test">
    <critical>üé≠ ECC ORCHESTRATOR: Spawning E2E Runner agent with full pre-flight context</critical>

    <output>üé≠ **Spawning E2E Runner...**

      Mode: {{e2e_action}}
      Target: {{target_spec}}
    </output>

    <ecc-spawn agent="e2e-runner">
      <task-call>
        subagent_type: "everything-claude-code:e2e-runner"
        description: "E2E test {{e2e_action}} for {{story_key}}"
        prompt: |
          ## E2E Test {{e2e_action}}: {{story_key}}

          **Mode:** {{e2e_action}}
          **Target:** {{target_spec}}

          **Pre-Flight Results:**
          - TestId Map: {{testid_map}}
          - Data Flow: {{data_flow_map}}
          - Environment: {{env_readiness}}
          - Cleanup Plan: {{cleanup_plan}}
          - Multi-User Strategy: {{multi_user_strategy}}

          **E2E Conventions (MUST follow):**
          {{e2e_conventions}}

          **Available Helpers (import from staging-helpers.ts):**
          {{staging_helpers_api}}

          **Cooldown Helpers (if needed):**
          {{cooldown_helpers}}

          **Selector Priority (from TEA):**
          1. data-testid (always preferred)
          2. getByRole with name
          3. Scoped locator within known container
          4. text= (last resort, breaks on translations)

          **Wait Strategy:**
          - Observable state: element.waitFor({ state: 'hidden/visible' })
          - Settling only: waitForTimeout(<1000ms)
          - NEVER: waitForTimeout(2000+) for async operations
          - NEVER: waitForLoadState('networkidle') with Firebase

          **Screenshot Convention:**
          - Directory: test-results/{spec-name}/ (PERSISTENT ‚Äî not cleaned by Playwright)
          - Playwright auto-artifacts (traces, videos): playwright-artifacts/ (cleaned per run)
          - Pattern: {step}-{description}.png
          - Capture at: page load, navigation, dialog open/close, form submit, final state
          - Re-running a spec only overwrites its own folder; other specs' screenshots persist

          **Viewport (MANDATORY):** { width: 360, height: 780 }

          **Test Users:** alice, bob, charlie, diana
          Auth: [data-testid="test-login-button"] ‚Üí [data-testid="test-user-{name}"]

          **Story ACs relevant to E2E:**
          {{story_acs_relevant_to_e2e}}

          **Requirements:**
          1. Follow ALL conventions from E2E-TEST-CONVENTIONS.md
          2. Use data-testid selectors ‚Äî NEVER bare text selectors
          3. Include try/finally cleanup matching the cleanup plan
          4. Add screenshots at every key interaction point
          5. Name test data with "E2E" prefix + Date.now() suffix
          6. If multi-user: implement {{multi_user_pattern}} pattern
          7. File size limits: E2E spec max 400 lines
      </task-call>
    </ecc-spawn>

    <action>Collect e2e-runner output as {{test_code}}</action>
    <action>Set {{test_file}} = path to created/modified spec file</action>

    <output>‚úÖ **E2E Test Written**

      File: {{test_file}}
      Mode: {{e2e_action}}
      Multi-User: {{multi_user_pattern}}
    </output>
  </step>

  <!-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê -->
  <!-- STEP 5: Run and Verify                                                 -->
  <!-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê -->

  <step n="5" goal="Run E2E test against staging and handle failures" tag="run-verify">

    <!-- Check staging availability -->
    <action>Check if dev:staging is running: `curl -s -o /dev/null -w "%{http_code}" http://localhost:5174`</action>

    <check if="dev:staging not running">
      <ask>‚ö†Ô∏è dev:staging is not running.

        Start it with: `npm run dev:staging`

        Confirm when ready: [R]eady / [A]bort</ask>
    </check>

    <!-- Run test -->
    <action>Run: `npx playwright test {{test_file}} --project=staging`</action>
    <action>Set {{run_attempt}} = 1</action>

    <check if="test fails and run_attempt <= 2">
      <action>Analyze failure:
        - Selector not found ‚Üí re-check TestId map, fix selector
        - Timeout ‚Üí check wait strategy, add polling/settling
        - State mismatch ‚Üí check optimistic update handling
        - Auth failure ‚Üí verify test user, re-login sequence
        - Flaky/timing ‚Üí add settling wait, increase timeout
      </action>
      <action>Fix identified issue in test file</action>
      <action>Increment {{run_attempt}}</action>
      <action>Set {{retries_needed}} = true</action>
      <action>Re-run: `npx playwright test {{test_file}} --project=staging`</action>
    </check>

    <check if="test fails after 2 retries">
      <ask>‚ùå E2E test failed after 2 retries.

        Error: {{error_summary}}
        Screenshots: {{screenshot_paths}}

        [F]ix manually / [S]kip test / [D]efer (create TD story for flaky test)</ask>

      <check if="user chooses D (Defer)">
        <action>Create TD story for flaky E2E test</action>
        <action>Set {{test_result}} = "DEFERRED"</action>
      </check>
    </check>

    <check if="test passes">
      <!-- Determinism check: run once more -->
      <action>Run again: `npx playwright test {{test_file}} --project=staging`</action>
      <check if="second run fails">
        <output>‚ö†Ô∏è **Flaky test detected** ‚Äî passed first run, failed second</output>
        <action>Set {{retries_needed}} = true</action>
        <action>Analyze flakiness source and fix</action>
      </check>
      <check if="second run passes">
        <action>Set {{test_result}} = "PASS"</action>
        <action>Set {{test_duration}} from Playwright output</action>
      </check>
    </check>

    <output>{{#if test_result == "PASS"}}‚úÖ{{else}}‚ö†Ô∏è{{/if}} **E2E Run Complete**

      Result: {{test_result}}
      File: {{test_file}}
      Duration: {{test_duration}}
      Retries needed: {{retries_needed}}
    </output>
  </step>

  <!-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê -->
  <!-- STEP 6: Post-Test Quality Check                                        -->
  <!-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê -->

  <step n="6" goal="Review E2E test quality using TEA 5-dimension scoring" tag="quality-review">
    <critical>üé≠ ECC ORCHESTRATOR: Spawning Code Reviewer for E2E quality assessment</critical>

    <ecc-spawn agent="code-reviewer">
      <task-call>
        subagent_type: "everything-claude-code:code-reviewer"
        description: "E2E quality review for {{test_file}}"
        prompt: |
          ## E2E Test Quality Review

          **Test file:** {{test_file}}
          **Story:** {{story_key}}
          **E2E Conventions:** {{e2e_conventions}}

          **Review checklist:**
          - Follows project E2E conventions?
          - Uses data-testid selectors (not fragile selectors)?
          - Has proper cleanup (try/finally)?
          - Screenshots at key interaction points?
          - Wait strategy correct (no networkidle, no long timeouts)?
          - Test data named with E2E prefix + timestamp?
          - Multi-user cleanup bidirectional (if applicable)?
          - File under 400 lines?

          **TEA 5-Dimension Quality Score (rate each 0-20, total /100):**
          1. **Determinism** ‚Äî No random/flaky patterns? No timing dependencies?
          2. **Isolation** ‚Äî No shared state leaking? Proper cleanup?
          3. **Maintainability** ‚Äî Uses staging-helpers? Follows conventions? Readable?
          4. **Coverage** ‚Äî Story ACs covered by assertions? Edge cases?
          5. **Performance** ‚Äî Runs within 60-120s budget? No unnecessary waits?

          **Output:** Score per dimension + total + any findings to fix.
      </task-call>
    </ecc-spawn>

    <action>Collect quality review as {{quality_review}}</action>
    <action>Extract {{quality_score}} (0-100) from review</action>
    <action>Extract {{quality_findings}} if any issues found</action>

    <check if="quality_findings has CRITICAL or HIGH severity">
      <action>Fix critical quality issues in test file</action>
      <action>Re-run test to verify fixes don't break it</action>
    </check>

    <output>‚úÖ **Quality Review Complete**

      TEA 5-Dimension Score: {{quality_score}}/100
      - Determinism: {{score_determinism}}/20
      - Isolation: {{score_isolation}}/20
      - Maintainability: {{score_maintainability}}/20
      - Coverage: {{score_coverage}}/20
      - Performance: {{score_performance}}/20

      {{#if quality_findings}}
      Findings: {{quality_findings_count}} ({{fixed_count}} fixed)
      {{/if}}
    </output>
  </step>

  <!-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê -->
  <!-- STEP 7: Update Story + TEA Escalation Assessment                       -->
  <!-- ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê -->

  <step n="7" goal="Update story with E2E results and assess TEA escalation" tag="completion">

    <!-- Update story Dev Notes -->
    <action>Add E2E results to story file:
      ```markdown
      ### E2E Testing
      - Action: {{e2e_action}}
      - Test File: {{test_file}}
      - Result: {{test_result}}
      - Multi-User: {{multi_user_pattern}}
      - Quality Score: {{quality_score}}/100
      - Date: {{date}}
      ```
    </action>

    <check if="story has E2E-related ACs">
      <action>Mark satisfied ACs in story file</action>
    </check>

    <check if="e2e_action == CREATE">
      <action>Add new test file to story File Specification</action>
    </check>

    <!-- TEA Escalation Assessment -->
    <action>Assess TEA escalation triggers:
      - {{quality_score}} < 60 ‚Üí flag
      - Multi-user concurrent + retries needed ‚Üí flag
      - >3 specs created/modified in this session ‚Üí flag
      - Last story in epic (check sprint-status.yaml) ‚Üí flag
    </action>

    <check if="any TEA escalation trigger fired">
      <output>üß™ **TEA Follow-Up Recommended**

        Reason: {{escalation_reason}}
        Suggested: {{suggested_tea_workflow}}
        Scope: {{escalation_scope}}
      </output>
    </check>

    <check if="no TEA escalation triggers">
      <action>Set {{tea_recommendation}} = "No TEA follow-up needed"</action>
    </check>

    <output>**‚úÖ ECC E2E Complete**

      **Story:** {{story_key}}
      **Action:** {{e2e_action}}
      **Result:** {{test_result}}
      **Quality:** {{quality_score}}/100

      **Test File:** {{test_file}}
      {{#if multi_user_pattern != "SINGLE-USER"}}
      **Multi-User:** {{multi_user_pattern}} ({{user_a}}, {{user_b}})
      {{/if}}

      {{#if tea_recommendation != "No TEA follow-up needed"}}
      **TEA:** {{tea_recommendation}}
      {{/if}}

      **Next Steps:**
      {{#if test_result == "PASS"}}
      - Commit E2E test with story changes
      - Run `ecc-code-review` if not yet done
      {{else}}
      - Fix failing test and re-run `/ecc-e2e`
      {{/if}}
    </output>
  </step>

</workflow>
