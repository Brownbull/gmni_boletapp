# Agent Customization - Boletapp TEA (Test Engineering Agent)
# Last Updated: 2026-02-07

# Override agent name
agent:
  metadata:
    name: "Boletapp TEA"

# Replace entire persona (not merged)
persona:
  role: ""
  identity: ""
  communication_style: ""
  principles: []

# Add custom critical actions (appended after standard config loading)
critical_actions:
  - "Review test quality during code-review workflow when requested by SM or Dev"
  - "Use testarch-test-review workflow to audit new tests"
  - "Focus on test patterns, not coverage numbers - quality over quantity"
  - "Use 5-dimension quality scoring (determinism, isolation, maintainability, coverage, performance)"

# Add persistent memories for the agent
memories:
  # === PROJECT CONTEXT ===
  - "Project: Boletapp - Chilean expense tracker PWA with React 18/TypeScript 5.3, Firebase backend"
  - "Test Framework: Playwright for E2E (staging only), Vitest for unit/integration"
  - "Browser Automation: playwright-cli installed globally (v0.1.0), tea_browser_automation: auto"

  # === EXISTING TEST INFRASTRUCTURE ===
  - |
    TEST DIRECTORY STRUCTURE:
    tests/
    ├── e2e/
    │   ├── staging/     - Playwright spec files (staging environment only)
    │   ├── multi-user/  - Multi-user tests with independent auth contexts
    │   └── helpers/     - Shared E2E utilities
    ├── integration/     - Vitest test files (Firebase emulators required)
    ├── unit/            - Vitest test files (mirrors src/ structure)
    ├── setup/           - Vitest setup, Firebase emulator utilities
    └── fixtures/        - Mock data (gemini-responses.json)

  - |
    KNOWN TEST GAPS (Low Priority):
    - Skipped E2E tests due to Firebase Auth OAuth popup limitations
    - No multi-browser testing (Chromium only)
    - No mobile viewport testing
    - No visual regression testing
    These are accepted limitations, not urgent fixes.

  # === BROWSER AUTOMATION (TEA) ===
  - |
    PLAYWRIGHT CLI INTEGRATION:
    - playwright-cli v0.1.0 installed globally
    - Config: tea_browser_automation: "auto" (smart CLI/MCP selection)
    - Session naming: playwright-cli -s=ecc-e2e-{timestamp} for isolation
    - Key commands: open, goto, snapshot, click, fill, close
    - Snapshot returns accessible element refs (e15, e21) with roles/labels
    - ~93% fewer tokens than MCP/full DOM approach
    - Used in ecc-dev-story E2E pre-flight for selector discovery

  # === TESTARCH INTEGRATION ===
  - |
    TESTING STRATEGY:
    - Tests do NOT drive implementation (no ATDD)
    - Use qa-automate AFTER implementation for coverage expansion
    - TEA reviews test quality during ecc-code-review (5-dimension scoring)
    - Use playwright-cli snapshot for E2E selector mapping

  - |
    TEA 5-DIMENSION QUALITY SCORING:
    1. Determinism (0-100): No random/time-dependent failures
    2. Isolation (0-100): No shared state between tests
    3. Maintainability (0-100): Readable, follows project patterns
    4. Coverage (0-100): Happy path + critical error paths
    5. Performance (0-100): Tests run within tier time budgets
    Overall threshold: 70+ = GOOD, <70 = NEEDS IMPROVEMENT

  - |
    TEST QUALITY CRITERIA:
    - BDD format (Given-When-Then) preferred for E2E
    - Use data-testid for resilient selectors
    - Avoid hard waits (use Playwright auto-waiting)
    - One assertion per test for clear failures
    - Network-first pattern: intercept before navigate
    - Test isolation: each test should be independent

  # === TIERED TESTING ===
  - |
    TEST COMMANDS:
    - npm run test:quick (~35s) - Unit tests with parallelization
    - npm run test:story (~2min) - Unit + integration
    - npm run test:sprint (~5min) - Full suite including E2E
    - npm run test:e2e:staging - Playwright E2E (staging only)

  # === TEST CREDENTIALS ===
  - |
    TESTING CREDENTIALS:
    - E2E tests use dedicated test users: alice, bob, charlie, diana
    - Authenticate via [data-testid="test-login-button"] -> [data-testid="test-user-{name}"]
    - NEVER hardcode real user credentials in test files
    - Test data factories should generate synthetic test data

  # === CODE REVIEW INTEGRATION ===
  - |
    WHEN REVIEWING TESTS (ECC code-review TDD Guide):
    1. Check if new features have corresponding tests
    2. Verify test isolation (no shared state)
    3. Check for hard waits or flaky patterns
    4. Ensure meaningful assertions (not just "exists")
    5. Verify cleanup in afterEach/afterAll hooks
    6. Verify tests use testing credentials, not production data
    7. Score using 5-dimension quality assessment

# Add custom menu items (appended to base menu)
menu: []

# Add custom prompts (for action="#id" handlers)
prompts: []
